\chapter{Interpolation}

\section* {Problème d'interpolation}
\begin{equation}
    f : [a,b] \longrightarrow \R
\end{equation}
Considérons des abscisses distinctes $X_i \in [a,b], i = 0,\cdots,n $.
\newline
On cherche un polynôme $P_n$ de degré $k \le n$ à coefficients réels, tel que :
\begin{equation}
    P_n(X_i) = f(X_i), i = 0,\cdots,n
\end{equation}

\begin{fdef}
    P est appelé polynôme d'interpolation.
\end{fdef}

On pose $Y_i = f(X_i)$.

% Graphique

\bigbreak
\bigbreak
\parindent=0em
Les termes principaux du problème :
\begin{enumerate}
\item Existence de solution
\item Unicité de la solution
\item Méthode de résolution
\item Qualité de la solution (préservation de la forme)
\end{enumerate}

% Graphique

\newpage

\section {Vandermonde}

Soit $(X_i, Y_i)$, avec $i = 0,\cdots,n$ et $X_i \ne X_j$

Le polynôme $P$ de degré $\le k$ qui doit interpoler $(X_i, Y_i)$ est :

\begin{equation}
    P_k(X) = \sum_{i = 0}^k a_i \cdot X^i \text{, $a_i \in \R$ }
\end{equation}


Différents cas :
\begin{itemize}
\item $k < n$ : en général pas de solution (moins de coefficients que de conditions à remplir)
\item $k > n$ : une infinité de solutions
\item $k = n$ : solution unique : système Vandermonde
\end{itemize}
% $k$ correspond notamment au nombre de colonnes de X.

\bigbreak
\bigbreak
Cette méthode ne concerne donc que le cas o\`u $k = n$, soit le polynôme :

\begin{equation}
    P_n(X) = \sum_{i = 0}^n a_i \cdot X^i \text{, $a_i \in \R$ }
\end{equation}

Les coefficients $a_i$ vérifient le système de $(n + 1)$ équations linéaires suivant :

\begin{equation}
    \sum_{i = 0}^n a_i \cdot X_j^i = Y_j \text{, $j = 0,\cdots,n$ }
\end{equation}


Forme matricielle :

\[
    \begin{array}{cc}
        \begin{pmatrix}
            1 & X_0 & X_0^2 & \cdots & X_0^n\\
            1 & X_1 & X_1^2 & \cdots & X_1^n\\
            & \vdots & \vdots & & \vdots\\
            1 & X_n & X_n^2 & \cdots & X_n^n
        \end{pmatrix}
        \cdot
        \begin{pmatrix}
            a_0\\
            a_1\\
            \vdots\\
            a_n
        \end{pmatrix}
        =
        \begin{pmatrix}
            Y_0\\
            Y_1\\
            \vdots\\
            Y_n
        \end{pmatrix}
    \end{array}
\]

Cette matrice de coefficients est connue comme matrice de Vandermonde V.


\begin{equation}
    \det(V) = \prod_{i = 0}^n \prod_{j = i + 1}^n (X_j - X_i)
\end{equation}

$\det(V) \ne 0 \Leftrightarrow$ $X_i$ distincts
\newline
\newline
$\Rightarrow$ Le système admet alors une solution unique.


\subsection* {Résolution}

\begin{itemize}
\item Coût : $O(n^3)$ opérations arithmétiques élémentaires ($+$, $-$, $\times$, $\div$)

Trop coûteux
\item Instable numériquement : le conditionnement de V peut être \og mauvais\fg

cond(V) $= ||V|| \cdot ||V^{-1}|| \ge 1$ (\og bon\fg  conditionnement quand cond(V) proche de 1)
\end{itemize}

Pour éviter ces problèmes, plusieurs méthodes explicites (sans résolution d'un système linéaire) existent.

$\rightarrow$ elles évitent en fait de calculer les coefficients $a_i$

$\rightarrow$ elles utilisent une autre représentation du polynôme $P_n$


\section {Méthode de Lagrange}

Polynômes de Lagrange de degré $k \le n$ :

\begin{equation}
    L_i(X) = \prod_{\substack{j = 0\\j \ne i}}^n \frac{X - X_j}{X_i - X_j}
\end{equation}

qui vérifient


\[
    L_i(X_j) = \delta _{ij} = \;
    \left\lbrace
    \begin{array}{cc|c}
            1 \text{ si i = j } \\
            0 \text{ si i $\ne$ j }
    \end{array}
    \right.
\]


Le polynôme d'interpolation :

\begin{equation}
    L_i(X) = \prod_{\substack{j = 0\\j \ne i}}^n \frac{X - X_j}{X_i - X_j}
\end{equation}

vérifie ainsi

\begin{equation}
    P_n(X_i) = \sum_{k = 0}^n Y_k L_k(X_i) = Y_i
\end{equation}



\subsection* {Résolution}

Coût : $O(n^2)$
\begin{itemize}
\item $O(n^2) = O(n) \cdot L_i(X)$ : calculer les $(n + 1)$ polynômes de base $L_i$
\item $O(n)$ : évaluation du polynôme
\end{itemize}

\bigbreak
Cette méthode se prête mal à la modification du nombre de points $X_i$, car elle force à recalculer tous les $L_i(X)$.


