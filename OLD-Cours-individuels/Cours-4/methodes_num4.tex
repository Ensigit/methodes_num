% definit le type de document et ses options
\documentclass[a4paper,11pt]{article}

% des paquetages utiles classiques, en ajouter d'autres selon vos besoins
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb,calc}
% \usepackage{fullpage}
% \usepackage{stmaryrd}
% \usepackage{url}
% \usepackage{xspace}
\usepackage[francais]{babel}

% Pour les matrices annotées ... 
\usepackage{blkarray}

% Pour les figures
\usepackage{graphicx}

% Pour les listes à puces
\usepackage{enumerate}

\usepackage{indentfirst}

% Évite un conflit entre french babel et enumitem
\frenchbsetup{StandardLists=true}

\usepackage[standard,framed]{ntheorem}
\usepackage{framed}

% Pour les matrices par blocs je crois ?
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother

% Pour annoter les matrices :
\usepackage{kbordermatrix} 
\renewcommand{\kbldelim}{(} % change default array delimiters to parentheses
\renewcommand{\kbrdelim}{)}


% Pour des matrices agrandies :
\newenvironment{bigmatrix}[2]{%
  \renewcommand*{\arraystretch}{#1}% 
  \begin{pmatrix}[#2]
}{%
  \end{pmatrix}
}

% Pour des commentaires à droite d'équations
\newenvironment{rcases}
  {\left.\begin{aligned}}
  {\end{aligned}\right\rbrace}

\newenvironment{lcases}
  {\left\lbrace\begin{aligned}}
  {\end{aligned}\right.}


\newcommand{\reff}[1]{(\ref{#1})}


\setlength{\parindent}{30pt}
\setlength{\parskip}{1ex}
\setlength{\textwidth}{15cm}
\setlength{\textheight}{24cm}
\setlength{\oddsidemargin}{0.2cm}
\setlength{\evensidemargin}{-.7cm}
\setlength{\topmargin}{-.5in}

% des commandes pratiques pour ecrire des maths :
\newcommand{\dx}{\,dx}
\newcommand{\dt}{\,dt}
\newcommand{\ito}{,\dotsc,}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Poly}[1]{\mathcal{P}_{#1}}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\pars}[1]{\left(#1\right)}
\newcommand{\bigpars}[1]{\bigl(#1\bigr)}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\tpo}[1]{\,^t#1}


\DeclareMathOperator{\Sup}{Sup}
\DeclareMathOperator{\Max}{Max}
\DeclareMathOperator{\Det}{Det}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\Min}{Min}

%
%\lstset{
%  literate=%
%  {À}{{\`A}}1 {Â}{{\^A}}1 {Ç}{{\c{C}}}1%
%  {à}{{\`a}}1 {â}{{\^a}}1 {ç}{{\c{c}}}1%
%  {É}{{\'E}}1 {È}{{\`E}}1 {Ê}{{\^E}}1 {Ë}{{\"E}}1% 
%  {é}{{\'e}}1 {è}{{\`e}}1 {ê}{{\^e}}1 {ë}{{\"e}}1%
%  {Ï}{{\"I}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1%
%  {ï}{{\"i}}1 {î}{{\^i}}1 {ô}{{\^o}}1%
%  {Ù}{{\`U}}1 {Û}{{\^U}}1 {Ü}{{\"U}}1%
%  {ù}{{\`u}}1 {û}{{\^u}}1 {ü}{{\"u}}1%
%}

\newlength\dlf
\newcommand\alignedbox[2]{
  % #1 = before alignment
  % #2 = after alignment
    &
    \begingroup
    \settowidth\dlf{$\displaystyle #1$}
    \addtolength\dlf{\fboxsep+\fboxrule}
    \hspace{-\dlf}
    \boxed{#1 #2}
\endgroup
}

%%%%% PACKAGE AMSTHM :
% \newtheoremstyle{definition}
%   {20pt}   % ABOVESPACE
%   {20pt}   % BELOWSPACE
%   {}  % BODYFONT
%   {0pt}       % INDENT (empty value is the same as 0pt)
%   {\bfseries} % HEADFONT
%   {.}         % HEADPUNCT
%   {5pt plus 1pt minus 1pt} % HEADSPACE
%   {}          % CUSTOM-HEAD-SPEC

\newframedtheorem{ftheo}[theorem]{Theoreme}

\theoremstyle{plain} % default
\theorembodyfont{\normalfont}
\newframedtheorem{fdef}[definition]{Définition}

\renewtheorem{remark}{Remarque}

\newframedtheorem{coroll}{Corollaire}

\newtheorem{rappel}{Rappel}

\newtheorem{preuve}{Preuve}

\title{\huge \bfseries Méthode de Gauss pour les systèmes linéaires et factorisation LU}
\date{}


\begin{document}
\maketitle

La méthode de Cholesky (ou Choleski) permet de résoudre des systèmes linéaires
dont la matrice est symétrique définie positive. On rappelle que
$A \in M_n(\R)$ est symétrique définie positive si et seulement si :
\begin{enumerate}
    \item $^tA = A$
    \item $^tXAX \geq 0, \forall x \in \R$
    \item $^tXAX = 0 \Rightarrow X = 0$
\end{enumerate}
Pour une matrice $A \in M_n(\R)$ symétrique, les propriétés 2) et 3) reviennent à supposer que toutes les valeurs propres de $A$ sont $> 0$.

On a également :
\begin{enumerate}
    \item $A$ définie positive $\Rightarrow$ $A$ inversible
    \item $A$ symétrique $\Rightarrow$ $A$ diagonalisable. $\exists P / A = P^{-1}DP$
    \item $A$ symétrique et définie positive $\Rightarrow$ toutes les valeurs propres de $A$ sont positives et réelles.
\end{enumerate}

Nous allons voir que les matrices pevuent se factoriser sous la forme $A = T\tpo{T}$ où
$T$ est triangulaire inférieure.

Pour résoudre $Ax = b$ ($x,b \in \R^n)$, càd $T\tpo{T}x=b$ on résout alors successivement :
\begin{equation*}
\left\lbrace
    \begin{array}{ccc}
        Ty  = & b & \text{ étape de ``descente''}\\
        \\
        \tpo{T}x  = & y & \text{ étape de ``remontée''}
    \end{array}
\right.
\end{equation*}

Cette méthode est bien sûr intéressante lorsqu'on doit résoudre plusieurs systèmes linéaires
avec des seconds membres $b$ différents, mais la même matrice $A$ (la factorisation est faite
une seule fois, et les étapes de descente et remontée pour chaque second membre).


\begin{ftheo}
    Soit $A \in M_n(\R)$ symétrique définie positive. Il existe (au moins) une matrice réelle triangulaire inférieure $T$ telle que :
    \[
        A = T \,^tT
    \]
    De plus, si on impose que les éléments diagonaux de T soient tous positifs, alors la factorisation $A = T \,^tT$ est unique.
\end{ftheo}


\begin{preuve}
    Les $n$ sous-matrices 
$\Delta _i =
\begin{pmatrix}
    a_{11} & \dots & a_{1i} \\
    \vdots & & \vdots \\
    a_{i1} & \dots & a_{ii}
\end{pmatrix}$
sont inversibles car elles sont symétriques définies positives. En effet, si 
$x =
\begin{pmatrix}
    x_1 \\
    \vdots \\
    x_i
\end{pmatrix}
$
et
$X =
\begin{pmatrix}
    x_1 \\
    \vdots \\
    x_i \\
    0 \\
    \vdots \\
    0
\end{pmatrix}
$
on a $\tpo{x} \Delta_i x = \tpo{X}AX$

Donc, d'après le théorème 2 du chapitre précédent, on a $A = LU$ avec $L$ triangulaire
inférieure de diagonale unité, et $U$ triangulaire supérieure inversible $(\rightarrow u_{ii} \ne 0 \forall i)$.
Notons $D = \diag{u_{ii}}$

On a : $A = \tpo{A} = \tpo{U} \tpo{L} = \underbrace{\tpo{U} D^{-1}}_\text{triang. inf de diagonale unité \hspace{0.2cm}}
\times
\underbrace{D \tpo{L}}_\text{triangulaire supérieure}$

Par unicité de la décomposition $LU$ il vient $D\tpo{L} = U$ et donc $A = L D \tpo{L}$. De plus, si $\tpo{L} V_i = e_i$

\[
    0 < \tpo{V_i} \, A \, V_i = \tpo{V_i} \, L \; D \; \tpo{L} \, V_i = \tpo{e_i} \, D \, e_i = u_{ii}
\]

Notons maintenant $\sqrt{D} = \diag{\sqrt{u_{ii}}}$. Alors $A = L \, \sqrt{D} \, \tpo{\sqrt{D}} \, \tpo{L}$,
c'est-à-dire $A = T \tpo{T}$ avec $T = L \sqrt{D}$.

L'unicité de la factorisation $A = T \tpo{T}$ vient de l'algorithme de calcul de $T$ décrit plus loin.
\end{preuve}


\subsection*{Calcul de T :}

T peut être calculé à partir d'une factorisation LU, mais on expose ici une méthode moins coûteuse en temps de calcul.

Puisque $A = T \tpo{T}$ avec $T$ triangulaire inférieure :

\[
    a_{ij} = \sum_{1 \leq k \leq \Min(i,j)} t_{ik} t_{jk}
\]

\begin{enumerate}[$-$]
    \item Calculons la 1\up{ère} colonne de $T$ à partir de celle de $A$ :
        \[
            a_{11} = t_{11}^2 \implies t_{11} = \sqrt{a_{11}} \hspace{1cm} 
            \text{($a_{11} > 0$ car $A$ symétrique définie positive)}
        \]
        Pour $i \geq 2$ :
        \[
            a_{i1} = t_{i1} t_{11} \implies t_{i1} = \frac{a_{i1}}{t_{11}}
        \]
    \item Supposons connues les colonnes $1$ à $p$ de $T$, et calculons la colonne $p+1$ :
        \begin{align*}
            & a_{p+1,p+1} = t_{p+1,p+1}^2 + \sum_{1 \leq k \leq p}(t_{p+1,k})^2 \to
            \text{calculés précédemment (colonnes 1 à $p$)} \\
            \implies & t_{p+1,p+1}^2 = a_{p+1,p+1} - \sum_{1 \leq k \leq p}(t_{p+1,k})^2 > 0 \hspace{0.5cm} \text{\underline{puisque $T$ existe}} \\
            \implies & t_{p+1,p+1} = \left(a_{p+1,p+1} - \sum_{1 \leq k \leq p}(t_{p+1,k})^2)\right)^{\frac{1}{2}}
        \end{align*}

        Pour $i \geq p+2$ :
        \begin{equation*}
            \begin{split}
                & a_{i,p+1} = t_{i,p+1} t_{p+1,p+1} + \sum_{1 \leq k \leq p}(t_{ik} t_{p+1,k})
            \hspace{1cm} \to \text{(calculés précédemment)} \\
                \implies & t_{i,p+1} = (a_{i,p+1} - \sum_{1 \leq k \leq p} t_{ik}t_{p+1,r} \frac{1}{t_{p+1,p+1}})
            \end{split}
        \end{equation*}

\end{enumerate}

\subsection*{Coût du calcul de T :}
On assimile l'extraction de racine carrée à une opération arithmétique élémentaire (ce qui est
une approximation, car cette opération est plus compliquée que les opérations élémentaires
$\times, +, -$ \dots).

Calcul de la 1\up{ère} colonne de $T$ : $n$ opérations.

Calcul de la $(p+1)$\up{ème} de $T$ :

\begin{enumerate}[$-$]
    \item Calcul de $t_{p+1,p+1}$ :
        \[
            \left.
            \parbox{4cm}{
                \begin{enumerate}[$*$]
                    \item $p$ multiplications
                    \item $p$ soustractions
                    \item $1$ racine
                \end{enumerate}
            }\right\rbrace \text{$2p+1$ opérations}
        \]

    \item Calcul de $t_{i,p+1} (p+2 \leq i \leq n)$ :
        \[
            \left.
            \parbox{4cm}{
                \begin{enumerate}[$*$]
                    \item $p$ multiplications
                    \item $p$ soustractions
                    \item $1$ divison
                \end{enumerate}
            }\right\rbrace \text{$2p+1$ opérations}
        \]
\end{enumerate}

$\to (n-p) \times (2p+1)$ opérations pour le calcul de la colonne $p+1$.

\begin{align*}
    \text{Coût total} & = \sum_{p=0}^{n-1} (n-p)(2p+1) \\
    & = (2n-1) \Bigg( \sum_{p=1}^{n-1}p \Bigg) + n^2 - 2 \sum_{p=1}^{n-1} p^2 \\
    & \sim_{n \to + \infty} n^3 - \frac{2}{3} n^3
\end{align*} 

Donc nombre d'opérations élémentaires $\sim_{n \to +\infty} \frac{1}{3}n^3$.
($\sim \frac{1}{6}n^3$ multiplications et $\frac{1}{6}n^3$ soustractions)


\subsection*{Coût de la résolution de $Ax = b$}

Le coût des étapes des descente et de remontée est $\mathcal{O}(n^2)$.

L'étape la plus coûteuse est donc la factorisation $A = T \tpo{T}$, et le coût total est $\sim \frac{1}{3}n^3$. C'est donc mieux que Gauss (coût $\sim \frac{2}{3}n^3)$.

\end{document}




